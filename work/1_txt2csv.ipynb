{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99c7178-d37c-4855-8d70-4267d615ad7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# --- 設定項目 ---\n",
    "# 処理対象のルートディレクトリ (元のデータが入っている場所)\n",
    "ROOT_DIR = './' \n",
    "# 分割したウィンドウを保存する新しいルートディレクトリ\n",
    "OUTPUT_ROOT_DIR = 'work_windowed'\n",
    "\n",
    "# 【変更点1】データトリミングの時間を定義できるようにする\n",
    "TRIM_START_SECONDS = 0.0  # 計測開始後、トリミングする秒数\n",
    "TRIM_END_SECONDS = 0.0    # 計測終了前、トリミングする秒数\n",
    "\n",
    "# タイムウィンドウの設定\n",
    "WINDOW_SIZE_SECONDS = 1.0  # 1秒間のウィンドウ\n",
    "OVERLAP_RATIO = 0.0 # 重複なし\n",
    "MIN_SAMPLES_PER_WINDOW = 5 \n",
    "\n",
    "# --- デバッグ情報表示 ---\n",
    "print(\"--- デバッグ情報 ---\")\n",
    "print(f\"カレントディレクトリ: {os.getcwd()}\")\n",
    "print(f\"入力ディレクトリ (ROOT_DIR): {os.path.abspath(ROOT_DIR)}\")\n",
    "print(f\"出力ディレクトリ (OUTPUT_ROOT_DIR): {os.path.abspath(OUTPUT_ROOT_DIR)}\")\n",
    "if not os.path.isdir(ROOT_DIR):\n",
    "    print(f\"\\n警告: 入力ディレクトリ '{ROOT_DIR}' が見つかりません。\")\n",
    "    print(\"スクリプトを 'work' ディレクトリと同じ階層に置いて実行していますか？\")\n",
    "print(\"--------------------\")\n",
    "\n",
    "print(f\"\\n処理を開始します。\")\n",
    "\n",
    "# 出力用のルートディレクトリを作成\n",
    "os.makedirs(OUTPUT_ROOT_DIR, exist_ok=True)\n",
    "\n",
    "# os.walkで指定したディレクトリ以下を再帰的に探索\n",
    "for dirpath, dirnames, filenames in os.walk(ROOT_DIR):\n",
    "    print(f\"\\n[探索中] ディレクトリ: {dirpath}\")\n",
    "    \n",
    "    # .ipynb_checkpointsのような不要なディレクトリは探索対象から除外\n",
    "    if '.ipynb_checkpoints' in dirnames:\n",
    "        dirnames.remove('.ipynb_checkpoints')\n",
    "\n",
    "    # 処理対象のファイルが3つ揃っているか確認\n",
    "    if 'x.txt' in filenames and 'y.txt' in filenames and 'z.txt' in filenames:\n",
    "        print(f\"  -> 発見: x.txt, y.txt, z.txt を含むディレクトリです。処理を開始します。\")\n",
    "        \n",
    "        try:\n",
    "            # --- ステップ1: 従来の前処理（統合とトリミング） ---\n",
    "            df_x = pd.read_csv(os.path.join(dirpath, 'x.txt'), header=None, names=['timestamp', 'x'])\n",
    "            df_y = pd.read_csv(os.path.join(dirpath, 'y.txt'), header=None, names=['timestamp', 'y'])\n",
    "            df_z = pd.read_csv(os.path.join(dirpath, 'z.txt'), header=None, names=['timestamp', 'z'])\n",
    "            \n",
    "            merged_df = df_x.copy()\n",
    "            merged_df['y'] = df_y['y']\n",
    "            merged_df['z'] = df_z['z']\n",
    "            \n",
    "            print(f\"    [前処理] 元データ読み込み完了。行数: {len(merged_df)}\")\n",
    "            if len(merged_df) == 0:\n",
    "                print(\"    [警告] 元データが空です。スキップします。\")\n",
    "                continue\n",
    "                \n",
    "            merged_df['timestamp'] = pd.to_datetime(merged_df['timestamp'])\n",
    "            duration_seconds = (merged_df['timestamp'].iloc[-1] - merged_df['timestamp'].iloc[0]).total_seconds()\n",
    "            print(f\"    [前処理] 元データの時間長: {duration_seconds:.2f} 秒\")\n",
    "\n",
    "            # 【変更点1】トリミング時間の合計を計算し、データ長が足りているかチェック\n",
    "            total_trim_seconds = TRIM_START_SECONDS + TRIM_END_SECONDS\n",
    "            if duration_seconds < total_trim_seconds:\n",
    "                print(f\"    [警告] データ長がトリミング時間({total_trim_seconds:.2f}秒)未満のため、スキップしました。\")\n",
    "                continue\n",
    "\n",
    "            # 【変更点1】設定した秒数でトリミング時間を決定\n",
    "            start_time = merged_df['timestamp'].iloc[0]\n",
    "            trim_start_time = start_time + pd.Timedelta(seconds=TRIM_START_SECONDS)\n",
    "            trim_end_time = merged_df['timestamp'].iloc[-1] - pd.Timedelta(seconds=TRIM_END_SECONDS)\n",
    "            \n",
    "            trimmed_df = merged_df[(merged_df['timestamp'] >= trim_start_time) & (merged_df['timestamp'] <= trim_end_time)].copy()\n",
    "            \n",
    "            print(f\"    [前処理] トリミング後のデータ行数: {len(trimmed_df)}\")\n",
    "\n",
    "            if trimmed_df.empty:\n",
    "                print(f\"    [警告] トリミング後にデータがなくなったため、処理をスキップしました。\")\n",
    "                continue\n",
    "\n",
    "            new_start_time = trimmed_df['timestamp'].iloc[0]\n",
    "            trimmed_df['time'] = (trimmed_df['timestamp'] - new_start_time).dt.total_seconds()\n",
    "            final_df = trimmed_df[['time', 'x', 'y', 'z']]\n",
    "\n",
    "            # 【変更点2】タイムウィンドウ化する前の時系列データをcsvで保存\n",
    "            pre_window_base_name = os.path.basename(dirpath) # 例: 'aruki1'\n",
    "            pre_window_output_filename = f\"{pre_window_base_name}.csv\" # 例: 'aruki1.csv'\n",
    "            pre_window_output_path = os.path.join(dirpath, pre_window_output_filename)\n",
    "            \n",
    "            final_df.to_csv(pre_window_output_path, index=False, float_format='%.6f')\n",
    "            print(f\"    [保存] ウィンドウ化前のデータを '{pre_window_output_path}' に保存しました。\")\n",
    "            \n",
    "            # --- ステップ2: タイムウィンドウ処理 ---\n",
    "            relative_path = os.path.relpath(dirpath, ROOT_DIR)\n",
    "            output_dir_path = os.path.join(OUTPUT_ROOT_DIR, relative_path)\n",
    "            os.makedirs(output_dir_path, exist_ok=True)\n",
    "            print(f\"    [ウィンドウ処理] 出力先ディレクトリ: {output_dir_path}\")\n",
    "\n",
    "            all_windows_list = []\n",
    "            \n",
    "            window_count = 0\n",
    "            step_size = WINDOW_SIZE_SECONDS * (1 - OVERLAP_RATIO)\n",
    "            current_pos = 0.0\n",
    "            total_duration = final_df['time'].iloc[-1]\n",
    "            \n",
    "            print(f\"    [ウィンドウ処理] 処理対象の時間長: {total_duration:.2f} 秒\")\n",
    "            \n",
    "            if total_duration < WINDOW_SIZE_SECONDS:\n",
    "                 print(f\"    [警告] 処理対象の時間長({total_duration:.2f}s)がウィンドウサイズ({WINDOW_SIZE_SECONDS}s)未満のため、ウィンドウを作成できません。\")\n",
    "\n",
    "            while current_pos + WINDOW_SIZE_SECONDS <= total_duration:\n",
    "                window_df = final_df[\n",
    "                    (final_df['time'] >= current_pos) & \n",
    "                    (final_df['time'] < current_pos + WINDOW_SIZE_SECONDS)\n",
    "                ].copy()\n",
    "\n",
    "                if len(window_df) >= MIN_SAMPLES_PER_WINDOW:\n",
    "                    all_windows_list.append(window_df)\n",
    "                    window_count += 1\n",
    "                \n",
    "                current_pos += step_size\n",
    "\n",
    "            if all_windows_list:\n",
    "                combined_df = pd.concat(all_windows_list, ignore_index=True)\n",
    "                combined_df.drop_duplicates(inplace=True)\n",
    "                combined_df.sort_values(by='time', inplace=True)\n",
    "                \n",
    "                base_name = os.path.basename(dirpath)\n",
    "                output_filename = f\"{base_name}_windowed_all.csv\"\n",
    "                output_path = os.path.join(output_dir_path, output_filename)\n",
    "                \n",
    "                combined_df.to_csv(output_path, index=False, float_format='%.6f')\n",
    "                \n",
    "                print(f\"  -> {window_count}個のウィンドウを結合し、'{output_filename}' に保存しました。\")\n",
    "            else:\n",
    "                print(\"  -> 作成された有効なウィンドウはありませんでした。\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"エラー: {dirpath} の処理中にエラーが発生しました - {e}\")\n",
    "\n",
    "print(\"\\nすべての処理が完了しました。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68998362-8415-40ac-b156-7e63a5dcc332",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# 処理対象のルートディレクトリ\n",
    "root_dir = './'\n",
    "\n",
    "print(f\"処理を開始します。ルートディレクトリ: {root_dir}\")\n",
    "\n",
    "# os.walkで指定したディレクトリ以下を再帰的に探索\n",
    "for dirpath, dirnames, filenames in os.walk(root_dir):\n",
    "    \n",
    "    # .ipynb_checkpointsのような不要なディレクトリは探索対象から除外\n",
    "    if '.ipynb_checkpoints' in dirnames:\n",
    "        dirnames.remove('.ipynb_checkpoints')\n",
    "\n",
    "    # 処理対象のファイルが3つ揃っているディレクトリかを判定\n",
    "    if 'x.txt' in filenames and 'y.txt' in filenames and 'z.txt' in filenames:\n",
    "        \n",
    "        print(f\"処理中のディレクトリ: {dirpath}\")\n",
    "        \n",
    "        try:\n",
    "            # --- 1. 各txtファイルを読み込み、DataFrameを作成 ---\n",
    "            df_x = pd.read_csv(os.path.join(dirpath, 'x.txt'), header=None, names=['timestamp', 'x'])\n",
    "            df_y = pd.read_csv(os.path.join(dirpath, 'y.txt'), header=None, names=['timestamp', 'y'])\n",
    "            df_z = pd.read_csv(os.path.join(dirpath, 'z.txt'), header=None, names=['timestamp', 'z'])\n",
    "            \n",
    "            # --- 2. データを統合し、タイムスタンプをdatetimeオブジェクトに変換 ---\n",
    "            # xのDataFrameをベースに、yとzの値を列として追加\n",
    "            merged_df = df_x.copy()\n",
    "            merged_df['y'] = df_y['y']\n",
    "            merged_df['z'] = df_z['z']\n",
    "            \n",
    "            # タイムスタンプの文字列をdatetimeオブジェクトに変換して時間計算を可能にする\n",
    "            merged_df['timestamp'] = pd.to_datetime(merged_df['timestamp'])\n",
    "\n",
    "            # --- 3. データの最初と最後の1秒をトリミング（削除） ---\n",
    "            # データ全体の長さが2秒未満の場合は処理をスキップ\n",
    "            if (merged_df['timestamp'].iloc[-1] - merged_df['timestamp'].iloc[0]).total_seconds() < 2:\n",
    "                print(f\"  警告: データ長が2秒未満のため、処理をスキップしました。\")\n",
    "                continue\n",
    "\n",
    "            # 削除する期間を定義\n",
    "            start_time = merged_df['timestamp'].iloc[0]\n",
    "            end_time = merged_df['timestamp'].iloc[-1]\n",
    "            trim_start_time = start_time + pd.Timedelta(seconds=1)\n",
    "            trim_end_time = end_time - pd.Timedelta(seconds=1)\n",
    "            \n",
    "            # 指定期間内のデータを抽出（.copy()で警告を回避）\n",
    "            trimmed_df = merged_df[(merged_df['timestamp'] > trim_start_time) & (merged_df['timestamp'] < trim_end_time)].copy()\n",
    "\n",
    "            # トリミング後にデータが空になった場合はスキップ\n",
    "            if trimmed_df.empty:\n",
    "                print(f\"  警告: トリミング後にデータがなくなったため、ファイルを作成しませんでした。\")\n",
    "                continue\n",
    "\n",
    "            # --- 4. 経過時間カラムを作成 ---\n",
    "            # トリミング後の先頭行の時刻を0秒とする\n",
    "            new_start_time = trimmed_df['timestamp'].iloc[0]\n",
    "            trimmed_df['time'] = (trimmed_df['timestamp'] - new_start_time).dt.total_seconds()\n",
    "            \n",
    "            # --- 5. 最終的なDataFrameを整形 ---\n",
    "            # 'timestamp'カラムを削除し、カラムの順序を'time, x, y, z'に指定\n",
    "            final_df = trimmed_df[['time', 'x', 'y', 'z']]\n",
    "\n",
    "            # --- 6. 統合・加工したデータをCSVとして保存 ---\n",
    "            dir_name = os.path.basename(dirpath)\n",
    "            output_filename = f\"{dir_name}_processed.csv\" # ファイル名が重複しないように変更\n",
    "            output_path = os.path.join(dirpath, output_filename)\n",
    "            \n",
    "            # index=FalseでDataFrameのインデックスがファイルに書き込まれるのを防ぐ\n",
    "            # float_formatで小数点以下の桁数を指定\n",
    "            final_df.to_csv(output_path, index=False, float_format='%.6f')\n",
    "            \n",
    "            print(f\"  -> 加工済みCSVを作成しました: {output_path}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"エラー: {dirpath} の処理中にエラーが発生しました - {e}\")\n",
    "\n",
    "print(\"\\nすべての処理が完了しました。\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
